Developed a custom VAE trained on the CelebA dataset (150k+ images) to learn disentangled latent representations — enabling controllable facial transformations like smile → neutral or short hair → long hair
Introduced a KL-free regularization strategy (inspired by DIP-VAE) using inverse variance penalties to ensure active, interpretable latent dimensions.
Implemented semantic attribute editing, style-content separation, and latent space traversal, demonstrating meaningful manipulation of high-level facial features.
